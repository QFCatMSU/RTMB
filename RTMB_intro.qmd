---
title: Fitting models via maximum likelihood using RTMB
title-slide-attributes:
    data-background-image: "https://qfcatmsu.github.io/Images/dark-big.png"  
    data-background-size: "40%"
    data-background-position: "7% 90%"
author: Chris Cahill and Jim Bence 
date: 21 July 2023
date-format: "D MMMM YYYY"
format: 
  revealjs:
    css: "https://qfcatmsu.github.io/css/presStyle.css"
    slide-number: c/t  
    theme: simple 
editor: visual
highlight-style: kate
---

## Outline

- Demonstrate a mind-blowing advance with AD
- Show a few examples that may be useful
    - Start with equations, move to code
- Talk about debugging via `browser()`
- Tips and trickery 
- Code for all of this available at: <https://github.com/QFCatMSU/RTMB/tree/main>

## What is RTMB?

- RTMB is a new package that provides a native R interface for a subset of TMB so you can avoid coding in C++
- See <https://kaskr.r-universe.dev/RTMB>
- In all applications we have tried all TMB functionality was available!
- Because code is all in R, both easier to code and for others to read that code -  a game changer!
- A game changer *if* you know how to code in R, create an objective f(x) for your model 
- No compiling or compiling errors!
- Bottom line: less time developing and testing models, more intuitive code 

## Linear regression in RTMB 

- The math: 

$$
y_{i}=\beta_{0}+\beta_{1} x_{i}+\epsilon_{i} \quad \text {where } \quad \epsilon_{i} \sim \operatorname{N}(0, \sigma)
$$ 

```{R echo = F}
# simulate and estimate a linear regression
n = 100 # n data
sd = 5 # sd of likelihood
b0 = 10 # intercept
b1 = 5 # slope

set.seed(123)
x1 = runif(n, -1, 1)
y_obs = rnorm(n, b0 + b1 * x1, sd)
```

```{R echo = T, fig.align = "center"}
par(mar=c(5,6,4,1) + 0.1)
plot(y_obs~x1, xlab = "x1", ylab = "observed data", cex.lab = 2.5)
```

## Linear regression (RTMB)

```{R echo = T}
# set up tagged data + parameters lists:
data = list(
  n = n,
  y_obs = y_obs,
  x1 = x1
)

pars = list(
  b0 = 1,
  b1 = 1,
  log_sd = log(3)
)

```

- see `linreg.r`

## Linear regression (RTMB)

```{R echo = T}
library(RTMB)

# write an objective function returning negative log-likelihood 
f = function(pars) {
  getAll(data, pars) # replaces DATA_XX, PARAMETER_YY
  y_pred = b0 + b1 * x1
  nll = -sum(dnorm(y_obs, y_pred, exp(log_sd), log = TRUE))
  nll
}

obj = MakeADFun(f, pars)
obj$fn() # objective function
obj$gr() # gradients

```

- Stick to base R 

## Linear regression (RTMB)

```{R echo = T}
opt = nlminb(obj$par, obj$fn, obj$gr)

```

## Linear regression (RTMB)

```{R echo = T}
sdr = sdreport(obj)
```
- We are done.

## Access fit

```{R echo = T}
opt
```

## Access fit

```{R echo = T}
sdr
```

# ***RTMB scales to (much) more complicated models***

## von Bertalanffy growth model: the math

<br><br>
$$
\begin{array}{l}
l_{i}=l_{\infty}\left(1-e^{-k\left(a_{i}-t_{0}\right)}\right)+\varepsilon_{i} \\
\varepsilon_{i} {\sim} \text{N}\left(0, \sigma^{2}\right)
\end{array}
$$

## RTMB objective f(x) for a von Bertalanffy growth model: 
```{R echo = T}
f = function(pars) {
  getAll(data, pars)
  linf = exp(log_linf)
  vbk = exp(log_vbk)
  sd = exp(log_sd)
  l_pred = linf * (1 - exp(-vbk * (age_i - t0)))
  nll = -sum(dnorm(l_obs_i, l_pred, sd, TRUE))
  REPORT(linf)
  REPORT(vbk)
  ADREPORT(sd)
  nll
}
```

- see `vonB.r`
- can use REPORT(), ADREPORT()

## Poisson GLMM: the math
<br>
$$
\begin{array}{l}
y_{i, site} \sim \text { Poisson}\left(\lambda_{i, site}\right) \\
\log \left(\lambda_{i, site}\right)=\beta_{0} + \beta_{1} \cdot x_{1}+\epsilon_{site} \\
\epsilon_{site} \sim \text{N}(0,\sigma^{2}_{site})
\end{array}
$$

- $\beta_{0}$ is global intercept shared among sites

- $x_{1}$ is a covariate 

- $\epsilon_{site}$ is normally distributed random effect 

## Objective f(x) for a Poisson GLMM: 
```{R echo = T}
f = function(pars) {
  getAll(data, pars)
  sd_site = exp(log_sd_site)                           # back transform
  jnll = 0                                             # initialize
  jnll = jnll - sum(dnorm(eps_site, 0, sd_site, TRUE)) # Pr(random effects)
  lam_i = exp(                                         # link f(x)
    Xmat %*% bvec +                                    # fixed effects
    eps_site                                           # random effects
  )
  jnll = jnll - sum(dpois(yobs, lam_i, TRUE))          # Pr(observations)
  jnll
}

```

- see `glmm.r`

## Objective f(x) for a hierarchical normal selectivity model, adapted from Millar and Freyer 1999: 

```{R echo = TRUE, eval  = FALSE, style= "font-size: 20.5pt;"}
f = function(pars) {
  getAll(data, pars)
  jnll = 0
  jnll = jnll - sum(dnorm(k1_dev, 0, exp(ln_sd_k1), TRUE))
  jnll = jnll - sum(dnorm(k2_dev, 0, exp(ln_sd_k2), TRUE))
  k1 = exp(ln_k1 + k1_dev)
  k2 = exp(ln_k2 + k2_dev)
  sel_mat = phi_mat = matrix(0, nrow(catches), ncol(catches))
  for (i in 1:nrow(sel_mat)) {
    for (j in 1:ncol(sel_mat)) {
      sel_mat[i, j] = exp(-(lens[i] - k1[site[i]] * rel_size[j])^2 /
        (2 * k2[site[i]]^2 * rel_size[j]^2))
    }
  }
  sel_sums = rowSums(sel_mat)
  for (i in 1:nrow(phi_mat)) {
    for (j in 1:ncol(phi_mat)) {
      phi_mat[i, j] = sel_mat[i, j] / sel_sums[i]
    }
  }
  jnll = jnll - sum(catches * log(phi_mat))
  jnll
}
  ```

- see `by_net.r`

## Spatially explicit Poisson GLMM: 
<br>
- see `glmm_spde.r`

## Spatial-temporal Poisson GLMM: 
<br>
- see `glmm_ar1spde.r`

## Conventional vonB with random $L_\infty$: math
$$
\begin{array}{c}
L_{i, j}=L_{\infty_i}\left(1-\exp \left(-K\left(a_{i, j}-t_{0}\right)))+\varepsilon_{i, j}\right.\right. \\
\varepsilon_{i, j} \sim N\left(0, \sigma^{2}\right) \\
\log \left(L_{\infty_i}\right) \sim N\left(\log \left(L_{\infty}\right), \sigma_{L \infty}^{2}\right)
\end{array}
$$

- Note $L_\infty$ is the median and not mean asymptote among ponds
- Also note, the model code uses likelihood equation with equivalent $L_{i, j} \sim N\left(\hat{L}_{i, j}, \sigma^{2}\right)$

## Objective f(x) for a Bence's vonB:

```{R echo = TRUE, eval  = FALSE, style= "font-size: 22.5pt;"}
f = function(pars) {
  getAll(data, pars)
  Linfmn = exp(logLinfmn)
  logLinfsd = exp(loglogLinfsd)
  Linfs = exp(logLinfs)
  K = exp(logK)
  Sig = exp(logSig)
  nponds = length(Linfs)
  nages = length(A)
  predL = matrix(0, nrow = nages, ncol = nponds)
  # fill one column (pond) at a time:
  for (i in 1:nponds) {
    predL[, i] = Linfs[i] * (1 - exp(-K * (A - t0)))
  }
  nll = -sum(dnorm(x = L, mean = predL, sd = Sig, log = TRUE))
  nprand = -sum(dnorm(x = logLinfs, mean = logLinfmn, sd = logLinfsd, log = TRUE))
  jnll = nll + nprand
  jnll
}
  ```

- see `multilinf.r`

## Objective f(x) for a Ricker stock-recruit model with a random walk $\alpha$: math 

TODO

## Objective f(x) for a Ricker stock-recruit model with a random walk $\alpha$

```{R echo = TRUE, eval  = FALSE, style= "font-size: 22.5pt;"}
f = function(pars) {
  getAll(data, pars)
  jnll =  0 # initialize
  # initial state
  jnll =  jnll - dnorm(alphas[1], exp(log_alpha0), exp(log_sd_alpha), TRUE)
  # walk through the remaining years
  for (t in 2:length(data$year)) {
    jnll =  jnll - dnorm(alphas[t], alphas[t - 1], exp(log_sd_alpha), TRUE)
  }
  # calculate systematic component:
  log_RS_pred =  alphas - beta * S
  # likelihood for observations vs. predictions:
  jnll =  jnll - sum(dnorm(log_RS_obs, log_RS_pred, exp(log_sdr), TRUE))
  REPORT(log_RS_pred)
  ADREPORT(alphas)
  jnll
}
  ```

- see `rw_ricker.r`

## Objective f(x) for a Ricker stock-recruit model with an AR-1 $\alpha$: math 

TODO

## Objective f(x) for an AR-1 Ricker $\alpha$

```{R echo = TRUE, eval  = FALSE, style= "font-size: 22.5pt;"}
to_cor =  function(x) { # -inf to inf --> -1 to 1 transform
  2 / (1 + exp(-2 * x)) - 1
}

f =  function(pars) {
  getAll(data, pars)
  n_year =  length(R)
  rho =  to_cor(trans_rho) # back transform
  sd_eps =  exp(log_sd_eps)
  sd_obs =  exp(log_sd_obs)
  jnll =  0
  jnll =  jnll - dnorm(eps_a[1], 0, sqrt(1 - rho^2) * sd_eps, TRUE) # initialize
  for (t in 2:n_year) {
    jnll =  jnll - dnorm(eps_a[t],                # current eps
                         rho * eps_a[t - 1],      # is a function of eps[t-1]
                         sqrt(1 - rho^2) * sd_eps, # + some stationary noise
                         TRUE
                        )
  }
  pred_log_R =  log_alpha + eps_a - beta * S + log(S)
  jnll =  jnll - sum(dnorm(log(R), pred_log_R, sd_obs, TRUE))
  jnll
}

```

- see `ar1_ricker.r`

## Debugging 

- Because RTMB is written in R, can use debugging tools (!)
- `browser()` allows you to step through and check calculations
  - no longer need `cout` or `REPORT()` calls to check calculations
- Can also use breakpoints
- Jump to demonstration (in-person)

## Tips 

- Talk about `advector` error messages
  - Often(?) means you are using something that isn't supported by RTMB
- Make sure you are using base R / RTMB f(x)'s
- Hash out each line to find the offending line(s)
- Discuss other oddities 

## Questions? 

<br><br>

- <cahill11@msu.edu>